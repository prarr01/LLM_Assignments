{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEq-oYpmSM5r"
   },
   "source": [
    "# **Text Summarization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:15.656114Z",
     "iopub.status.busy": "2024-08-11T16:03:15.655701Z",
     "iopub.status.idle": "2024-08-11T16:03:24.968346Z",
     "shell.execute_reply": "2024-08-11T16:03:24.967306Z",
     "shell.execute_reply.started": "2024-08-11T16:03:15.656079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.0.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[K     |████████████████████████████████| 289 kB 68.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:24.970881Z",
     "iopub.status.busy": "2024-08-11T16:03:24.970466Z",
     "iopub.status.idle": "2024-08-11T16:03:29.797029Z",
     "shell.execute_reply": "2024-08-11T16:03:29.796097Z",
     "shell.execute_reply.started": "2024-08-11T16:03:24.970814Z"
    },
    "id": "lisXNzYrYOoR",
    "outputId": "4ff65cf3-36bb-49c2-a6c3-08070c9233a0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K \n",
    "from tensorflow.python.keras.layers import Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSr24NviXqio"
   },
   "source": [
    "# **Import Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet sets up the environment to load a CSV file containing news summaries into a pandas DataFrame and displays the first few rows to inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:29.799422Z",
     "iopub.status.busy": "2024-08-11T16:03:29.799047Z",
     "iopub.status.idle": "2024-08-11T16:03:30.669877Z",
     "shell.execute_reply": "2024-08-11T16:03:30.668986Z",
     "shell.execute_reply.started": "2024-08-11T16:03:29.799381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Specifying the Path to the Dataset\n",
    "data_path = '../news_summary.csv'\n",
    "\n",
    "#Loading the Dataset\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "#Displaying the First Few Rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:30.671490Z",
     "iopub.status.busy": "2024-08-11T16:03:30.671228Z",
     "iopub.status.idle": "2024-08-11T16:03:30.719263Z",
     "shell.execute_reply": "2024-08-11T16:03:30.718503Z",
     "shell.execute_reply.started": "2024-08-11T16:03:30.671465Z"
    },
    "id": "Mis8W95SAZ5_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Removing Duplicates\n",
    "data.drop_duplicates(subset=['headlines'],inplace=True)\n",
    "\n",
    "#Resetting the Index\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocess function performs several steps to clean and standardize text data:\n",
    "* Converts text to lowercase.\n",
    "* Expands contractions.\n",
    "* Removes stop words.\n",
    "* Removes possessive 's and periods.\n",
    "* Removes text within parentheses.\n",
    "* Replaces non-alphanumeric characters (except periods and spaces) with spaces.\n",
    "* Ensures spaces follow periods.\n",
    "* Replaces multiple spaces with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:30.720643Z",
     "iopub.status.busy": "2024-08-11T16:03:30.720389Z",
     "iopub.status.idle": "2024-08-11T16:03:30.729282Z",
     "shell.execute_reply": "2024-08-11T16:03:30.728497Z",
     "shell.execute_reply.started": "2024-08-11T16:03:30.720617Z"
    },
    "id": "BV8b6w9YYOoa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Loading Stop Words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#Defining the preprocess Function\n",
    "def preprocess(text):\n",
    "    \n",
    "    #Converting Text to Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Expanding Contractions\n",
    "    text = ' '.join([contractions.fix(word) for word in text.split(\" \")])    \n",
    "    \n",
    "    #Removing Stop Words\n",
    "    tokens = [w for w in text.split() if not w in stop_words]\n",
    "    \n",
    "    #Additional Text Cleaning\n",
    "    text = \" \".join(tokens)\n",
    "    text = text.replace(\"'s\",'')\n",
    "    text = text.replace(\".\",'')\n",
    "    text = re.sub(r'\\(.*\\)','',text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9. ]',' ',text)\n",
    "    text = re.sub(r'\\.','. ',text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    #Returning the Cleaned Text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code preprocesses the text data in both the 'headlines' and 'text' columns, adds special tokens to the 'headlines', and prints the first two examples.\n",
    "* **Preprocessing Columns**: Both the 'headlines' and 'text' columns are preprocessed to clean and standardize the text using the preprocess function defined earlier. This ensures that the text is in a consistent format, which is crucial for tasks like text summarization or machine learning.\n",
    "* **Adding Tokens**: The start (_START_) and end (_END_) tokens are added to the 'headlines' to indicate the beginning and end of the summary. This is often done in sequence-to-sequence models, such as those used in text generation or summarization, to help the model understand where the summary starts and ends.\n",
    "* **Printing Examples**: Printing the first two processed entries allows for a quick inspection to ensure that the preprocessing steps have been applied correctly and to see examples of the formatted text and summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:03:30.730801Z",
     "iopub.status.busy": "2024-08-11T16:03:30.730437Z",
     "iopub.status.idle": "2024-08-11T16:04:22.377292Z",
     "shell.execute_reply": "2024-08-11T16:04:22.376302Z",
     "shell.execute_reply.started": "2024-08-11T16:03:30.730760Z"
    },
    "id": "ewSx5cepYOob",
    "outputId": "55b255a6-367f-4443-8184-650066137e32",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "_START_ upgrad learner switches career ml al 90 salary hike _END_\n",
      "Text:\n",
      "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
      "\n",
      "Summary:\n",
      "_START_ delhi techie wins free food swiggy one year cred _END_\n",
      "Text:\n",
      "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cultfit more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the 'headlines' Column\n",
    "data['headlines'] = data['headlines'].apply(preprocess)\n",
    "\n",
    "#Preprocessing the 'text' Column\n",
    "data['text'] = data['text'].apply(preprocess)\n",
    "\n",
    "#Adding Start and End Tokens to 'headlines'\n",
    "data['headlines'] = data['headlines'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
    "\n",
    "#Printing Processed Examples\n",
    "for i in range(2):\n",
    "    print('Summary:', data['headlines'][i],'Text:', data['text'][i], sep='\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided lines of code generate two lists: headlines_length and text_length. Each element in these lists represents the number of words in a corresponding entry in the 'headlines' and 'text' columns, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:04:22.379091Z",
     "iopub.status.busy": "2024-08-11T16:04:22.378677Z",
     "iopub.status.idle": "2024-08-11T16:04:22.708622Z",
     "shell.execute_reply": "2024-08-11T16:04:22.707818Z",
     "shell.execute_reply.started": "2024-08-11T16:04:22.379049Z"
    },
    "id": "Tb68xRjGNP8z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Calculating the Lengths of 'headlines'\n",
    "headlines_length = [len(x.split()) for x in data.headlines]\n",
    "\n",
    "#Calculating the Lengths of 'text'\n",
    "text_length = [len(x.split()) for x in data.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a figure with two side-by-side histograms to visualize the distribution of word counts in the 'headlines' and 'text' columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:04:22.711899Z",
     "iopub.status.busy": "2024-08-11T16:04:22.711513Z",
     "iopub.status.idle": "2024-08-11T16:04:24.369967Z",
     "shell.execute_reply": "2024-08-11T16:04:24.369126Z",
     "shell.execute_reply.started": "2024-08-11T16:04:22.711860Z"
    },
    "id": "4exx0vZpoZDp",
    "outputId": "4fcef4de-8331-4731-b6af-be6b525e8351",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating a Figure and Subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "\n",
    "#Plotting Histograms\n",
    "ax1.hist(headlines_length, bins = 20)\n",
    "ax2.hist(text_length, bins = 20)\n",
    "\n",
    "#Setting Titles for Subplots\n",
    "ax1.title.set_text(\"Words in Headlines\")\n",
    "ax2.title.set_text(\"Words in Text\")\n",
    "\n",
    "#Displaying the Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J6b2-BXoasR"
   },
   "source": [
    "# **Embedding Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below sets up for using GloVe embeddings by specifying the embedding size (300 dimensions) and opening the GloVe embeddings file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:04:24.372172Z",
     "iopub.status.busy": "2024-08-11T16:04:24.371907Z",
     "iopub.status.idle": "2024-08-11T16:04:24.381414Z",
     "shell.execute_reply": "2024-08-11T16:04:24.380708Z",
     "shell.execute_reply.started": "2024-08-11T16:04:24.372147Z"
    },
    "id": "7vLovzKr0m5S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Setting the Embedding Size\n",
    "glove_size = 300\n",
    "\n",
    "#Opening the GloVe Embeddings File\n",
    "f = open('../input/glove42b300dtxt/glove.42B.300d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below reads the pre-trained GloVe word embeddings from a file and stores them in a dictionary called embeddings_index. Each word in the dictionary is associated with its corresponding 300-dimensional word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:04:24.383078Z",
     "iopub.status.busy": "2024-08-11T16:04:24.382676Z",
     "iopub.status.idle": "2024-08-11T16:08:27.594489Z",
     "shell.execute_reply": "2024-08-11T16:08:27.593634Z",
     "shell.execute_reply.started": "2024-08-11T16:04:24.383041Z"
    },
    "id": "KulasZGc0nDp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Creating an Empty Dictionary for Embeddings\n",
    "embeddings_index = dict()\n",
    "\n",
    "#Iterating Over Each Line in the File\n",
    "for line in f:\n",
    "    \n",
    "    #Processing Each Line\n",
    "    values = line.split()\n",
    "    \n",
    "    #Storing the Word and Its Embedding in the Dictionary\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "    \n",
    "#Closing the File\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet processes the text data to:\n",
    "* Collect all words and unique words in the corpus.\n",
    "* Compare the unique words with the GloVe vocabulary to determine how many words have corresponding GloVe vectors.\n",
    "* Create a dictionary of word vectors for the words in the corpus that have corresponding GloVe vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:27.596011Z",
     "iopub.status.busy": "2024-08-11T16:08:27.595699Z",
     "iopub.status.idle": "2024-08-11T16:08:28.971438Z",
     "shell.execute_reply": "2024-08-11T16:08:28.970558Z",
     "shell.execute_reply.started": "2024-08-11T16:08:27.595982Z"
    },
    "id": "7JA07ZzL0nhw",
    "outputId": "5535e162-8446-4832-a2e9-82c5eb2dd588",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the words in the corpus 3664472\n",
      "the unique words in the corpus 89937\n",
      "The number of words that are present in both glove vectors and our corpus are 70870 which is nearly 79.0% \n",
      "word 2 vec length 70870\n"
     ]
    }
   ],
   "source": [
    "#Collecting All Words in the Corpus\n",
    "words_source_train = []\n",
    "for i in data['text'] :\n",
    "  words_source_train.extend(i.split(' '))\n",
    "\n",
    "#Printing the Total Number of Words in the Corpus\n",
    "print(\"all the words in the corpus\", len(words_source_train))\n",
    "\n",
    "#Identifying Unique Words in the Corpus\n",
    "words_source_train = set(words_source_train)\n",
    "print(\"the unique words in the corpus\", len(words_source_train))\n",
    "\n",
    "#Finding Intersection with GloVe Vocabulary\n",
    "inter_words = set(embeddings_index.keys()).intersection(words_source_train)\n",
    "print(\"The number of words that are present in both glove vectors and our corpus are {} which \\\n",
    "is nearly {}% \".format(len(inter_words), np.round((float(len(inter_words))/len(words_source_train))\n",
    "*100)))\n",
    "\n",
    "#Creating a Dictionary of Word Vectors for the Corpus\n",
    "words_corpus_source_train = {}\n",
    "words_glove = set(embeddings_index.keys())\n",
    "for i in words_source_train:\n",
    "  if i in words_glove:\n",
    "    words_corpus_source_train[i] = embeddings_index[i]\n",
    "print(\"word 2 vec length\", len(words_corpus_source_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the code cell below:\n",
    "* **Purpose**: This line of code identifies and prints a sample of words from the corpus that do not have corresponding GloVe vectors. This can help us understand which words in our corpus are missing from the pre-trained embeddings and may need to be handled separately (e.g., by using random vectors, learning embeddings from scratch, or ignoring them).\n",
    "* **Use Case**: This is useful for diagnosing coverage issues with the embeddings and understanding the extent to which our corpus differs from the vocabulary covered by the GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:28.972764Z",
     "iopub.status.busy": "2024-08-11T16:08:28.972481Z",
     "iopub.status.idle": "2024-08-11T16:08:28.982327Z",
     "shell.execute_reply": "2024-08-11T16:08:28.981525Z",
     "shell.execute_reply.started": "2024-08-11T16:08:28.972735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'dainotti', 'kichad', 'meetpal', 'basisnot', 'itsjustajacket', 'compromisedimpartiality', 'withinif', 'godno', 'khangarot', 'gulabnabi', '4daystest', 'imppa', 'vrajlal', 'owlers', 'sharvi', 'ganeshotav', 'buttlers', 'saena', 'zappfresh']\n"
     ]
    }
   ],
   "source": [
    "#Finding and Printing Words Not in GloVe\n",
    "print(list(words_source_train - inter_words)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a function to count words in each text entry of a DataFrame that are not present in a predefined set of words with GloVe vectors. This count is then added as a new column in the DataFrame, allowing for analysis of the extent to which words in the text are missing from the GloVe embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:28.983717Z",
     "iopub.status.busy": "2024-08-11T16:08:28.983430Z",
     "iopub.status.idle": "2024-08-11T16:08:29.780005Z",
     "shell.execute_reply": "2024-08-11T16:08:29.778555Z",
     "shell.execute_reply.started": "2024-08-11T16:08:28.983657Z"
    },
    "id": "hT_Ak7qtkv2_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Defining the Function num\n",
    "def num(text):\n",
    "  words = [w for w in text.split() if not w in inter_words]\n",
    "  return len(words)\n",
    "\n",
    "#Applying the Function to the DataFrame\n",
    "data['unique_words'] = data['text'].apply(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **value_counts**() method on the 'unique_words' column provides a count of how many entries have each unique number of words that are missing from the GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:29.782053Z",
     "iopub.status.busy": "2024-08-11T16:08:29.781622Z",
     "iopub.status.idle": "2024-08-11T16:08:29.926446Z",
     "shell.execute_reply": "2024-08-11T16:08:29.925659Z",
     "shell.execute_reply.started": "2024-08-11T16:08:29.782009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73902\n",
       "1    15827\n",
       "2     5772\n",
       "3     1973\n",
       "4      559\n",
       "5      173\n",
       "6       59\n",
       "7       11\n",
       "8        4\n",
       "Name: unique_words, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['unique_words'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet filters the DataFrame data to retain only those rows where the number of unique words not present in GloVe embeddings is less than 4. It then resets the index of the DataFrame to ensure that it is sequential and free from gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:29.928268Z",
     "iopub.status.busy": "2024-08-11T16:08:29.927925Z",
     "iopub.status.idle": "2024-08-11T16:08:30.028745Z",
     "shell.execute_reply": "2024-08-11T16:08:30.028042Z",
     "shell.execute_reply.started": "2024-08-11T16:08:29.928238Z"
    },
    "id": "N4RZLvQ00zBN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Filtering Rows\n",
    "data = data[data['unique_words'] < 4]\n",
    "\n",
    "#Resetting the Index\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:30.030386Z",
     "iopub.status.busy": "2024-08-11T16:08:30.030034Z",
     "iopub.status.idle": "2024-08-11T16:08:30.044349Z",
     "shell.execute_reply": "2024-08-11T16:08:30.043522Z",
     "shell.execute_reply.started": "2024-08-11T16:08:30.030349Z"
    },
    "id": "uF08PoBm1N78",
    "outputId": "b54f44b1-d68b-428c-d37d-37f691f00573",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_START_ upgrad learner switches career ml al 9...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit b pg program m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_START_ delhi techie wins free food swiggy one...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_START_ new zealand end rohit sharma led india...</td>\n",
       "      <td>new zealand defeated india 8 wickets fourth od...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_START_ aegon life iterm insurance plan helps ...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_START_ known hirani yrs metoo claims true son...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97469</th>\n",
       "      <td>_START_ crpf jawan axed death maoists chhattis...</td>\n",
       "      <td>crpf jawan tuesday axed death sharp edged weap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97470</th>\n",
       "      <td>_START_ first song sonakshi sinha noor titled ...</td>\n",
       "      <td>uff yeh first song sonakshi sinha starrer upc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97471</th>\n",
       "      <td>_START_  the matrix film get reboot reports _END_</td>\n",
       "      <td>according reports new version 1999 science fic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97472</th>\n",
       "      <td>_START_ snoop dogg aims gun clown dressed trum...</td>\n",
       "      <td>new music video shows rapper snoop dogg aiming...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97473</th>\n",
       "      <td>_START_ madhesi morcha withdraws support nepal...</td>\n",
       "      <td>madhesi morcha alliance seven political partie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97474 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "0      _START_ upgrad learner switches career ml al 9...   \n",
       "1      _START_ delhi techie wins free food swiggy one...   \n",
       "2      _START_ new zealand end rohit sharma led india...   \n",
       "3      _START_ aegon life iterm insurance plan helps ...   \n",
       "4      _START_ known hirani yrs metoo claims true son...   \n",
       "...                                                  ...   \n",
       "97469  _START_ crpf jawan axed death maoists chhattis...   \n",
       "97470  _START_ first song sonakshi sinha noor titled ...   \n",
       "97471  _START_  the matrix film get reboot reports _END_   \n",
       "97472  _START_ snoop dogg aims gun clown dressed trum...   \n",
       "97473  _START_ madhesi morcha withdraws support nepal...   \n",
       "\n",
       "                                                    text  unique_words  \n",
       "0      saurav kant alumnus upgrad iiit b pg program m...             0  \n",
       "1      kunal shah credit card bill payment platform c...             2  \n",
       "2      new zealand defeated india 8 wickets fourth od...             0  \n",
       "3      aegon life iterm insurance plan customers enjo...             0  \n",
       "4      speaking sexual harassment allegations rajkuma...             0  \n",
       "...                                                  ...           ...  \n",
       "97469  crpf jawan tuesday axed death sharp edged weap...             0  \n",
       "97470   uff yeh first song sonakshi sinha starrer upc...             2  \n",
       "97471  according reports new version 1999 science fic...             0  \n",
       "97472  new music video shows rapper snoop dogg aiming...             0  \n",
       "97473  madhesi morcha alliance seven political partie...             0  \n",
       "\n",
       "[97474 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code performs two sequential splits on the dataset to create three subsets:\n",
    "* **Training Set (X_train, y_train)**: 80% of the data used to train the model.\n",
    "* **Validation Set (X_val, y_val)**: 10% of the data used to tune model parameters and avoid overfitting.\n",
    "* **Test Set (X_test, y_test)**: 10% of the data used to evaluate the final model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:30.045635Z",
     "iopub.status.busy": "2024-08-11T16:08:30.045360Z",
     "iopub.status.idle": "2024-08-11T16:08:30.072708Z",
     "shell.execute_reply": "2024-08-11T16:08:30.071917Z",
     "shell.execute_reply.started": "2024-08-11T16:08:30.045608Z"
    },
    "id": "5JaGAWYn7kqR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#First Split: Train and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data['text'], data['headlines'], test_size = 0.2, random_state = 20)\n",
    "\n",
    "#Second Split: Validation and Test Sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size = 0.5, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines of code in the cell below calculate and store the lengths of the longest text and headline in the dataset. The maximum lengths are essential for preparing the data for machine learning models, ensuring that all sequences are of a consistent size by padding or truncating them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:30.074102Z",
     "iopub.status.busy": "2024-08-11T16:08:30.073798Z",
     "iopub.status.idle": "2024-08-11T16:08:30.081285Z",
     "shell.execute_reply": "2024-08-11T16:08:30.080434Z",
     "shell.execute_reply.started": "2024-08-11T16:08:30.074074Z"
    },
    "id": "zhoRlF5L_qwa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length_x = max(text_length)\n",
    "max_length_y = max(headlines_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process in the cell below transforms raw text data into a format that can be used by machine learning models, ensuring that all input sequences have a consistent size and are represented as integer indices.\n",
    "* **Tokenizer Initialization and Fitting**: The Tokenizer is used to create a vocabulary from all the texts and headlines, mapping each word to a unique integer.\n",
    "* **Vocabulary Size**: The vocabulary size is determined and adjusted to include an index for padding.\n",
    "* **Text to Sequences**: Texts are converted to sequences of integers based on the vocabulary.\n",
    "* **Padding Sequences**: Sequences are padded to ensure they all have the same length, making them suitable for input into neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:30.082577Z",
     "iopub.status.busy": "2024-08-11T16:08:30.082320Z",
     "iopub.status.idle": "2024-08-11T16:08:40.225964Z",
     "shell.execute_reply": "2024-08-11T16:08:40.225013Z",
     "shell.execute_reply.started": "2024-08-11T16:08:30.082553Z"
    },
    "id": "QXQdLrLK0l5B",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Creating and Fitting the Tokenizer\n",
    "x_t = Tokenizer()\n",
    "x_t.fit_on_texts(data['text'] + data['headlines'])\n",
    "\n",
    "#Getting Vocabulary Size\n",
    "x_vocab_size = len(x_t.word_index) + 1\n",
    "\n",
    "#Encoding Texts into Sequences\n",
    "encoded_xtrain = x_t.texts_to_sequences(X_train)\n",
    "encoded_xval = x_t.texts_to_sequences(X_val)\n",
    "encoded_xtest = x_t.texts_to_sequences(X_test)\n",
    "\n",
    "#Padding Sequences\n",
    "padded_xtrain = pad_sequences(encoded_xtrain, maxlen=max_length_x, padding='post')\n",
    "padded_xval = pad_sequences(encoded_xval, maxlen=max_length_x, padding='post')\n",
    "padded_xtest = pad_sequences(encoded_xtest, maxlen=max_length_x, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:40.227532Z",
     "iopub.status.busy": "2024-08-11T16:08:40.227235Z",
     "iopub.status.idle": "2024-08-11T16:08:44.406196Z",
     "shell.execute_reply": "2024-08-11T16:08:44.405161Z",
     "shell.execute_reply.started": "2024-08-11T16:08:40.227501Z"
    },
    "id": "n7SVsptTNPtP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Creating and Fitting the Tokenizer\n",
    "y_t = Tokenizer()\n",
    "y_t.fit_on_texts(data['headlines'])\n",
    "\n",
    "#Getting Vocabulary Size\n",
    "y_vocab_size = len(y_t.word_index) + 1\n",
    "\n",
    "#Encoding Texts into Sequences\n",
    "encoded_ytrain = y_t.texts_to_sequences(y_train)\n",
    "encoded_yval = y_t.texts_to_sequences(y_val)\n",
    "encoded_ytest = y_t.texts_to_sequences(y_test)\n",
    "\n",
    "#Padding Sequences\n",
    "padded_ytrain = pad_sequences(encoded_ytrain, maxlen=max_length_y, padding='post')\n",
    "padded_yval = pad_sequences(encoded_yval, maxlen=max_length_y, padding='post')\n",
    "padded_ytest = pad_sequences(encoded_ytest, maxlen=max_length_y, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding matrix will be used in our model to provide pre-trained word vectors as input, improving the model's ability to understand and process text based on GloVe's semantic embeddings.\n",
    "* **Loaded Word Vectors**: The number of word vectors loaded from GloVe is printed to verify successful loading.\n",
    "* **Embedding Matrix Initialization**: A matrix is created to hold the word embeddings for the vocabulary. This matrix will be used in the model to represent words with their GloVe vectors.\n",
    "* **Matrix Population**: The embedding matrix is populated with GloVe vectors for words that exist in the vocabulary. Words not found in GloVe remain as zeros, which are usually handled by the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:44.407745Z",
     "iopub.status.busy": "2024-08-11T16:08:44.407450Z",
     "iopub.status.idle": "2024-08-11T16:08:44.719497Z",
     "shell.execute_reply": "2024-08-11T16:08:44.718547Z",
     "shell.execute_reply.started": "2024-08-11T16:08:44.407715Z"
    },
    "id": "rM-974HV0nKo",
    "outputId": "6aa27890-eaf7-4e0f-e594-8057efa18be6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Printing the Count of Loaded Vectors\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#Initializing the Embedding Matrix\n",
    "embedding_matrix = np.zeros((x_vocab_size, glove_size))\n",
    "\n",
    "#Populating the Embedding Matrix\n",
    "for word, i in x_t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99aPNL7dqnfh"
   },
   "source": [
    "# **Model Creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AttentionLayer implements a custom attention mechanism using a specific architecture:\n",
    "* **Weights**: W_a, U_a, and V_a are used for computing attention scores.\n",
    "* **Attention Computation**: The energy_step function calculates attention scores, and the context_step function computes the context vectors.\n",
    "* **Initial States**: Dummy initial states are created for the RNN computations.\n",
    "* **RNN Operations**: The attention mechanism is applied using K.rnn to calculate attention scores and context vectors.\n",
    "* **Output Shapes**: The output shapes are defined for the context vectors and attention scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:44.721325Z",
     "iopub.status.busy": "2024-08-11T16:08:44.720943Z",
     "iopub.status.idle": "2024-08-11T16:08:44.739671Z",
     "shell.execute_reply": "2024-08-11T16:08:44.738731Z",
     "shell.execute_reply.started": "2024-08-11T16:08:44.721284Z"
    },
    "id": "GWuQ1AG8OdVL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "          \n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  \n",
    "            \n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            \n",
    "            fake_state = K.zeros_like(inputs)  \n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  \n",
    "            fake_state = K.expand_dims(fake_state)  \n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  \n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  \n",
    "\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code constructs a sequence-to-sequence model with an attention mechanism:\n",
    "* **Encoder**: Uses a stack of LSTM layers to process the input sequence.\n",
    "* **Decoder**: Uses an LSTM layer initialized with the encoder's final states to generate output sequences.\n",
    "* **Attention Mechanism**: Enhances the decoder by focusing on relevant parts of the encoder's output.\n",
    "* **Final Layer**: Applies a dense layer to predict the next token in the sequence at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:44.742989Z",
     "iopub.status.busy": "2024-08-11T16:08:44.742677Z",
     "iopub.status.idle": "2024-08-11T16:08:49.619986Z",
     "shell.execute_reply": "2024-08-11T16:08:49.619047Z",
     "shell.execute_reply.started": "2024-08-11T16:08:44.742959Z"
    },
    "id": "wTukjl0hpPgo",
    "outputId": "6035a9eb-baac-43ff-a123-74e1ae1f02b7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 57)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 57, 300)      27025200    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 57, 500), (N 1602000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 57, 500), (N 2002000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    27025200    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 57, 500), (N 2002000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  1602000     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 34797)  34831797    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 96,590,697\n",
      "Trainable params: 42,540,297\n",
      "Non-trainable params: 54,050,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "latent_dim=500\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "encoder_inputs = Input(shape=(max_length_x,)) \n",
    "enc_emb = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False)(encoder_inputs) \n",
    "\n",
    "#LSTM \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Decoder. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup ensures efficient training by saving the best model and preventing overfitting through early stopping.\n",
    "* **Compiling**: Configures the model for training with the Adam optimizer and sparse categorical crossentropy loss.\n",
    "* **Callbacks**: Includes model checkpointing to save the best model and early stopping to halt training if validation loss does not improve.\n",
    "* **Training**: Trains the model for 10 epochs with a batch size of 512, using both training and validation data, and applying the specified callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:08:49.621524Z",
     "iopub.status.busy": "2024-08-11T16:08:49.621235Z",
     "iopub.status.idle": "2024-08-11T16:26:34.054130Z",
     "shell.execute_reply": "2024-08-11T16:26:34.053304Z",
     "shell.execute_reply.started": "2024-08-11T16:08:49.621497Z"
    },
    "id": "4fUJoaFAiwUb",
    "outputId": "4bc22143-d3ed-4b87-e2e6-c44f3034a816",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "153/153 [==============================] - 118s 690ms/step - loss: 5.4743 - val_loss: 4.4699\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 104s 681ms/step - loss: 4.4097 - val_loss: 4.2363\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 104s 681ms/step - loss: 4.0204 - val_loss: 3.8174\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 3.5541 - val_loss: 3.5855\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 104s 679ms/step - loss: 3.1652 - val_loss: 3.4143\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 2.8113 - val_loss: 3.3238\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 2.5028 - val_loss: 3.2647\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 2.2461 - val_loss: 3.2349\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 2.0423 - val_loss: 3.2209\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 104s 680ms/step - loss: 1.8596 - val_loss: 3.2097\n"
     ]
    }
   ],
   "source": [
    "#Model Compilation\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "#Model Checkpoint\n",
    "checkpoint_filepath = './model.{epoch:02d}-{val_loss:.2f}.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,\n",
    "                                                               monitor='val_loss',\n",
    "                                                               mode='min',\n",
    "                                                               save_best_only=True, \n",
    "                                                               save_freq = \"epoch\")\n",
    "\n",
    "#Early Stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\n",
    "\n",
    "#Model Training\n",
    "history=model.fit([padded_xtrain,padded_ytrain[:,:-1]], padded_ytrain.reshape(padded_ytrain.shape[0],padded_ytrain.shape[1], 1)[:,1:] ,\n",
    "                  epochs=10,\n",
    "                  batch_size=512, \n",
    "                  validation_data=([padded_xval,padded_yval[:,:-1]], padded_yval.reshape(padded_yval.shape[0],padded_yval.shape[1], 1)[:,1:]), \n",
    "                  callbacks=[es, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:26:38.555797Z",
     "iopub.status.busy": "2024-08-11T16:26:38.555428Z",
     "iopub.status.idle": "2024-08-11T16:26:39.222150Z",
     "shell.execute_reply": "2024-08-11T16:26:39.221210Z",
     "shell.execute_reply.started": "2024-08-11T16:26:38.555764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from ./model.10-3.21.h5\n"
     ]
    }
   ],
   "source": [
    "def find_best_model_file(directory, pattern=\"model.*.h5\"):\n",
    "    files = os.listdir(directory)\n",
    "    best_loss = float('inf')\n",
    "    best_model_file = None\n",
    "    \n",
    "    for file in files:\n",
    "        match = re.search(r'(\\d+\\.\\d+)\\.h5$', file)\n",
    "        if match:\n",
    "            val_loss = float(match.group(1))\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model_file = file\n",
    "    \n",
    "    return os.path.join(directory, best_model_file) if best_model_file else None\n",
    "\n",
    "# Load the best model weights\n",
    "best_model_filepath = find_best_model_file('./')\n",
    "if best_model_filepath:\n",
    "    model.load_weights(best_model_filepath)\n",
    "    print(f\"Loaded weights from {best_model_filepath}\")\n",
    "else:\n",
    "    print(\"No model file found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:26:42.076255Z",
     "iopub.status.busy": "2024-08-11T16:26:42.075916Z",
     "iopub.status.idle": "2024-08-11T16:26:50.385882Z",
     "shell.execute_reply": "2024-08-11T16:26:50.384940Z",
     "shell.execute_reply.started": "2024-08-11T16:26:42.076227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 8s 27ms/step - loss: 3.2097\n",
      "Validation loss after loading best weights: 3.2096872329711914\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate([padded_xval, padded_yval[:, :-1]], padded_yval.reshape(padded_yval.shape[0], padded_yval.shape[1], 1)[:, 1:])\n",
    "print(f\"Validation loss after loading best weights: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet of code is used to load a previously saved model's weights and recompile it. \n",
    "* **Reconstructing the Model**: Recreates the model architecture to match the one used during training. This step is crucial because the model needs to have the same structure to correctly load the weights.\n",
    "* **Loading Weights**: Loads the weights from a specific file into the reconstructed model. This allows us to use the trained model’s parameters without retraining.\n",
    "* **Recompiling**: Sets up the model with the same optimizer and loss function used during training, preparing it for evaluation or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:26.260831Z",
     "iopub.status.busy": "2024-08-11T16:27:26.260485Z",
     "iopub.status.idle": "2024-08-11T16:27:26.926232Z",
     "shell.execute_reply": "2024-08-11T16:27:26.925299Z",
     "shell.execute_reply.started": "2024-08-11T16:27:26.260801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Reconstructing the Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#Loading Weights\n",
    "model.load_weights(\"./model.10-3.21.h5\")\n",
    "\n",
    "#Recompiling the Model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CULXhQiGpvO"
   },
   "source": [
    "This code creates a plot showing how the training and validation loss change over epochs. This visualization helps in understanding the model's performance during training:\n",
    "* **Training Loss (train)**: Indicates how well the model is fitting the training data.\n",
    "* **Validation Loss (test)**: Indicates how well the model is generalizing to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:30.797964Z",
     "iopub.status.busy": "2024-08-11T16:27:30.797604Z",
     "iopub.status.idle": "2024-08-11T16:27:30.944074Z",
     "shell.execute_reply": "2024-08-11T16:27:30.943197Z",
     "shell.execute_reply.started": "2024-08-11T16:27:30.797931Z"
    },
    "id": "JQf1v5WhqLLg",
    "outputId": "f5bfa510-79c7-465e-e371-ea5b36198da9",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "\n",
    "#Plotting Training and Validation Loss\n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ0W3VZorHVK"
   },
   "source": [
    "# **Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mappings below are crucial for tasks such as converting model predictions back into readable words or for analyzing and interpreting the model’s output.\n",
    "* **reverse_target_word_index**: Maps indices to words for the target vocabulary.\n",
    "* **reverse_source_word_index**: Maps indices to words for the source vocabulary.\n",
    "* **target_word_index**: Maps words to indices for the target vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:30.945626Z",
     "iopub.status.busy": "2024-08-11T16:27:30.945370Z",
     "iopub.status.idle": "2024-08-11T16:27:30.949199Z",
     "shell.execute_reply": "2024-08-11T16:27:30.948452Z",
     "shell.execute_reply.started": "2024-08-11T16:27:30.945601Z"
    },
    "id": "UlSTzEbnskcd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Reverse Target Word Index\n",
    "reverse_target_word_index = y_t.index_word \n",
    "\n",
    "#Reverse Source Word Index\n",
    "reverse_source_word_index = x_t.index_word \n",
    "\n",
    "#Target Word Index\n",
    "target_word_index = y_t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are used together for generating sequences during inference. The encoder processes the input sequence, and the decoder generates the output sequence step-by-step, using the attention mechanism to focus on relevant parts of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:31.119261Z",
     "iopub.status.busy": "2024-08-11T16:27:31.118948Z",
     "iopub.status.idle": "2024-08-11T16:27:31.436992Z",
     "shell.execute_reply": "2024-08-11T16:27:31.436096Z",
     "shell.execute_reply.started": "2024-08-11T16:27:31.119230Z"
    },
    "id": "thX0Ep0Ssnd1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Encoder Model\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "#Decoder Model\n",
    "#Defining Input Layers for Decoder\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_length_x,latent_dim))\n",
    "\n",
    "#Decoder Embedding and LSTM\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "#Concatenate and Dense Layer\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#Attention Mechanism\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "\n",
    "#Concatenate and Dense Layer\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "#Define Decoder Model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is typically used for generating predictions\n",
    "* **Encoding**: The input sequence is processed by the encoder to obtain the encoder outputs and states.\n",
    "* **Decoding**: The decoder generates the sequence one token at a time using the attention mechanism and updated states.\n",
    "* **Termination**: The loop continues until an end token is generated or the sentence reaches the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:31.440627Z",
     "iopub.status.busy": "2024-08-11T16:27:31.440345Z",
     "iopub.status.idle": "2024-08-11T16:27:31.448146Z",
     "shell.execute_reply": "2024-08-11T16:27:31.447339Z",
     "shell.execute_reply.started": "2024-08-11T16:27:31.440598Z"
    },
    "id": "wtU0wU8gsuz1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Function Definition\n",
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    #Preprocessing Input Sequence\n",
    "    input_seq= input_seq.reshape(1,max_length_x)\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Initialization\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    #Decoding Loop\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "  \n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    " \n",
    "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_length_y-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    #Return Decoded Sentence\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both functions below are useful for interpreting model outputs and inputs by translating numerical representations back into human-readable form.\n",
    "* **seq2summary**: Converts a target sequence from indices to a readable summary text, excluding special tokens like start and end tokens.\n",
    "* **seq2text**: Converts a source sequence from indices to a readable text, excluding padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:31.593327Z",
     "iopub.status.busy": "2024-08-11T16:27:31.593016Z",
     "iopub.status.idle": "2024-08-11T16:27:31.603312Z",
     "shell.execute_reply": "2024-08-11T16:27:31.602264Z",
     "shell.execute_reply.started": "2024-08-11T16:27:31.593300Z"
    },
    "id": "cLyRVENRs2Ay",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Function: seq2summary\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "#Function: seq2text\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below evaluates the performance of the sequence-to-sequence model by comparing the original summaries with the predicted summaries for a sample of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:31.926732Z",
     "iopub.status.busy": "2024-08-11T16:27:31.926403Z",
     "iopub.status.idle": "2024-08-11T16:27:38.240800Z",
     "shell.execute_reply": "2024-08-11T16:27:38.239895Z",
     "shell.execute_reply.started": "2024-08-11T16:27:31.926696Z"
    },
    "id": "bXrWSc9Es5Qr",
    "outputId": "08e094bf-5b7a-4d2d-9042-f01c9390c8df",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: former lieutenant governor najeeb jung disapproved delhi government proposed premium bus scheme last year government monday announced plans app based bus service project least 1 000 buses run private operators service aims reduce use private vehicles state transport minister kailash gahlot said \n",
      "Original summary: delhi government plans app based bus service \n",
      "Predicted summary:  ex vacant prez proposes charge new york\n",
      "\n",
      "\n",
      "Review: slamming odisha bjd government suicide girl claimed raped four men uniform congress bjp called separate demonstrations state wide shutdown thursday elaborate safety arrangements made police schools colleges state remain shut safety students \n",
      "Original summary: cong bjp call odisha bandh rape victim suicide \n",
      "Predicted summary:  bjp mla booked rape victim pradesh police rape\n",
      "\n",
      "\n",
      "Review: former south african captain graeme smith former windies captain darren sammy accused australian coaches favouring australian players teams playing xi ipl despite poor form players questioned selection australians including rr d arcy short dd glenn maxwell kxip aaron finch notably rr srh dd kxip australian coaches \n",
      "Original summary: smith sammy accuse aus ipl coaches favouring aus players \n",
      "Predicted summary:  ex aus captain smith coaching cricket team\n",
      "\n",
      "\n",
      "Review: us intelligence agencies alerted indian counterpart threat lone wolf attack islamic state global entrepreneurship summit 2017 hyderabad summit attended us president donald trump daughter ivanka intelligence bureau telangana counter intelligence cell tightened security scrutinising 200 suspects terror links \n",
      "Original summary: us intel alerts lone wolf attack ges 2017 \n",
      "Predicted summary:  us embassy un chief global terrorist terror attack\n",
      "\n",
      "\n",
      "Review: video pakistani journalist sitting inflated pool flooded road lahore gone viral video begins close up reporter wherein says might seem swimming pool actually flooded road journalist asks people use technique enjoy \n",
      "Original summary: video pak journalist floating pool road goes viral \n",
      "Predicted summary:  video shows army officer guarding flood hit\n",
      "\n",
      "\n",
      "Review: india added 91 million new taxpayers financial year 2016 2017 due demonetisation high valued notes witnessing increase 80 annual average notably india 559 million individual taxpayers end 2015 2016 fiscal year reportedly india adds around six million taxpayers around one million stop paying taxes due death retirement every year \n",
      "Original summary: 80 increase new taxpayers 2016 2017 due note ban \n",
      "Predicted summary:  india gdp growth rate 75 lakh per month report\n",
      "\n",
      "\n",
      "Review: mumbai based venture capital fund unicorn india ventures invested undisclosed sums three kerala based startups said statement startups humanoid developer genrobotic innovations smart kitchen appliances maker sectorqube body scanning firm perfectfit fashion vc fund made investments across 10 startups since inception 2015 \n",
      "Original summary: unicorn india ventures backs three kerala based startups \n",
      "Predicted summary:  mumbai based lightbox startup funded raises 2 crore\n",
      "\n",
      "\n",
      "Review: actress priyanka chopra revealed five years old found asthma talking health problem tweeted i knew control asthma controlled me long got inhaler asthma cannot stop achieving goals \n",
      "Original summary: 5 found asthma priyanka chopra \n",
      "Predicted summary:  cancer kids life size cancer diagnosis\n",
      "\n",
      "\n",
      "Review: german police stated arrested russian football hooligan wanted attempted homicide england supporter euro 2016 fan violence police said detained wanted man arrival munich airport en route bilbao 31 year old travelling european league match \n",
      "Original summary: russian hooligan arrested homicide attempt euro 2016 \n",
      "Predicted summary:  russian man jailed knife attack football\n",
      "\n",
      "\n",
      "Review: haryana bjp state president subhash barala son friend arrested saturday allegedly stalking daughter ias officer chandigarh woman complaint alleged two men chased bike accused reportedly influence alcohol \n",
      "Original summary: haryana bjp state chief son arrested stalking woman \n",
      "Predicted summary:  bjp mla son booked raping woman assaulting\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(\"Review:\",seq2text(padded_xtest[i]))\n",
    "  print(\"Original summary:\",seq2summary(padded_ytest[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(padded_xtest[i]))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3Sfc9a422Rg"
   },
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km13viOn2P4t"
   },
   "source": [
    "The **BLEU_Score** function is designed to evaluate the quality of machine-generated summaries by calculating the **BLEU** (Bilingual Evaluation Understudy) score. BLEU is a metric for evaluating the quality of text generated by a model compared to reference texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:38.242538Z",
     "iopub.status.busy": "2024-08-11T16:27:38.242256Z",
     "iopub.status.idle": "2024-08-11T16:27:38.247564Z",
     "shell.execute_reply": "2024-08-11T16:27:38.246672Z",
     "shell.execute_reply.started": "2024-08-11T16:27:38.242511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Function Definition\n",
    "def BLEU_Score(y_test, y_pred):\n",
    "    \n",
    "    #Convert Target Summary (y_test) to Readable Text:\n",
    "    references = [[seq2summary(y_test).split(\" \")]]\n",
    "    \n",
    "    #Convert Predicted Summary (y_pred) to Readable Text:\n",
    "    candidates = [decode_sequence(y_pred.reshape(1,max_length_x)).split(\" \")]\n",
    "    \n",
    "    #Compute BLEU Score:\n",
    "    return corpus_bleu(references, candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet calculates and prints the average BLEU score for the first 500 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:27:38.249641Z",
     "iopub.status.busy": "2024-08-11T16:27:38.249354Z",
     "iopub.status.idle": "2024-08-11T16:30:56.122392Z",
     "shell.execute_reply": "2024-08-11T16:30:56.121429Z",
     "shell.execute_reply.started": "2024-08-11T16:27:38.249601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5654092000883735\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#Initialize an Empty List:\n",
    "scores=[]\n",
    "\n",
    "#Loop Through First 500 Test Samples:\n",
    "for i in range(0,500):\n",
    "    \n",
    "    #Calculate BLEU Score for Each Sample:\n",
    "    scores.append(BLEU_Score(padded_ytest[i],padded_xtest[i]))\n",
    "    \n",
    "#Calculate and Print the Average BLEU Score:\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Universal Sentence Encoder is designed to provide embeddings for sentences\n",
    "* **Purpose**: To load a pre-trained Universal Sentence Encoder model from TensorFlow Hub, which can be used to convert sentences into vector embeddings for various natural language processing tasks.\n",
    "* **Inputs**: The URL of the pre-trained model.\n",
    "* **Outputs**: A confirmation message that the model has been successfully loaded and is ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:30:56.124396Z",
     "iopub.status.busy": "2024-08-11T16:30:56.124021Z",
     "iopub.status.idle": "2024-08-11T16:31:26.926095Z",
     "shell.execute_reply": "2024-08-11T16:31:26.925094Z",
     "shell.execute_reply.started": "2024-08-11T16:30:56.124354Z"
    },
    "id": "Z516n1wQSgn1",
    "outputId": "83eac699-47fc-4854-a02e-b39ed8af9f50",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "\n",
    "#Define the URL for the Model:\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "#Load the Model from TensorFlow Hub:\n",
    "sentence_encoder = hub.load(module_url)\n",
    "\n",
    "#Print Confirmation Message:\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity score provides a way to evaluate how closely the generated summaries match the actual summaries in terms of their semantic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:57:55.622937Z",
     "iopub.status.busy": "2024-08-11T16:57:55.622519Z",
     "iopub.status.idle": "2024-08-11T16:57:55.629453Z",
     "shell.execute_reply": "2024-08-11T16:57:55.628551Z",
     "shell.execute_reply.started": "2024-08-11T16:57:55.622894Z"
    },
    "id": "phm5tVv6yCZ9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Function Definition\n",
    "def cosine_similarity(padded_xval, padded_yval):\n",
    "    \n",
    "    #Initialize an Empty List for Scores:\n",
    "    scores = []\n",
    "    for i in range(len(padded_xval)):\n",
    "        \n",
    "        #Convert Token Sequences to Text:\n",
    "        str1 = seq2summary(padded_yval[i])\n",
    "        str2 = decode_sequence(padded_xval[i])\n",
    "        \n",
    "        #Get Sentence Embeddings:\n",
    "        embeddings = sentence_encoder([str1, str2]).numpy()\n",
    "        \n",
    "        #Compute Cosine Similarity:\n",
    "        result = 1 - spatial.distance.cosine(embeddings[0], embeddings[1])\n",
    "        \n",
    "        #Append the Similarity Score:\n",
    "        scores.append(result)\n",
    "        \n",
    "    #Return the List of Scores:\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T16:57:56.246064Z",
     "iopub.status.busy": "2024-08-11T16:57:56.245699Z",
     "iopub.status.idle": "2024-08-11T17:01:29.301965Z",
     "shell.execute_reply": "2024-08-11T17:01:29.301060Z",
     "shell.execute_reply.started": "2024-08-11T16:57:56.246033Z"
    },
    "id": "SoB-bWnvcNC9",
    "outputId": "a83b5641-48b0-4ac3-916c-7a0b6d62f644",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4240491009671241"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute Cosine Similarity Scores:\n",
    "scores = cosine_similarity(padded_xtest[:500],padded_ytest[:500] )\n",
    "\n",
    "#Calculate the Mean Cosine Similarity Score:\n",
    "np.mean(scores)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 213609,
     "sourceId": 464671,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1895,
     "sourceId": 791838,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30121,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
